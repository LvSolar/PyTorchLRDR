{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1 ä¸€äº›çç¢ä»£ç "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 RNNCell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "output size: torch.Size([1, 2])\n",
      "tensor([[-0.4140,  0.1517]], grad_fn=<TanhBackward0>)\n",
      "==================== 1 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "output size: torch.Size([1, 2])\n",
      "tensor([[-0.4725, -0.7875]], grad_fn=<TanhBackward0>)\n",
      "==================== 2 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "output size: torch.Size([1, 2])\n",
      "tensor([[-0.8257, -0.2262]], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "\n",
    "# Construction of RNNCell\n",
    "cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
    "# Wrapping the sequence into:(seqLen,batchSize,InputSize)\n",
    "dataset = torch.randn(seq_len, batch_size, input_size)  # (3,1,4)\n",
    "# Initializing the hidden to zero\n",
    "hidden = torch.zeros(batch_size, hidden_size)  # (1,2)\n",
    "\n",
    "for idx, input in enumerate(dataset):\n",
    "    print('=' * 20, idx, '=' * 20)  #åˆ†å‰²çº¿ï¼Œ20ä¸ª=å·\n",
    "    print('Input size:', input.shape)  # (batch_size, input_size)\n",
    "    # æŒ‰åºåˆ—ä¾æ¬¡è¾“å…¥åˆ°cellä¸­ï¼Œseq_len=3ï¼Œæ•…å¾ªç¯3æ¬¡\n",
    "    hidden = cell(input, hidden)  # è¿”å›çš„hiddenæ˜¯ä¸‹ä¸€æ¬¡çš„è¾“å…¥ä¹‹ä¸€ï¼Œå¾ªç¯ä½¿ç”¨åŒä¸€ä¸ªcell\n",
    "\n",
    "    print('output size:', hidden.shape)  # (batch_size, hidden_size)\n",
    "    print(hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([3, 1, 2])\n",
      "Output: tensor([[[-0.9880, -0.8818]],\n",
      "\n",
      "        [[ 0.6066,  0.9090]],\n",
      "\n",
      "        [[-0.3108,  0.7957]]], grad_fn=<StackBackward0>)\n",
      "Hidden size: torch.Size([1, 1, 2])\n",
      "Hidden: tensor([[[-0.3108,  0.7957]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1  # RNNå±‚æ•°\n",
    "\n",
    "# Construction of RNN\n",
    "rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "# Wrapping the sequence into:(seqLen,batchSize,InputSize)\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)  # (3,1,4)\n",
    "# Initializing the hidden to zero\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)  # (1,1,2)\n",
    "\n",
    "output, hidden = rnn(inputs, hidden)  # RNNå†…éƒ¨åŒ…å«äº†å¾ªç¯ï¼Œæ•…è¿™é‡Œåªéœ€æŠŠæ•´ä¸ªåºåˆ—è¾“å…¥å³å¯\n",
    "\n",
    "print('Output size:', output.shape)  # (seq_len, batch_size, hidden_size)\n",
    "print('Output:', output)\n",
    "print('Hidden size:', hidden.shape)  # (num_layers, batch_size, hidden_size)\n",
    "print('Hidden:', hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 RNNå‚æ•°ï¼šbatch_first"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([1, 3, 2])\n",
      "Output: tensor([[[ 0.6276, -0.1454],\n",
      "         [ 0.0294,  0.3148],\n",
      "         [-0.3239,  0.4692]]], grad_fn=<TransposeBackward1>)\n",
      "Hidden size: torch.Size([1, 1, 2])\n",
      "Hidden: tensor([[[-0.3239,  0.4692]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1  # RNNå±‚æ•°\n",
    "\n",
    "# Construction of RNN, batch_first=True\n",
    "rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "# ä»…è¿™é‡Œåšäº†æ›´æ”¹ Wrapping the sequence into:(batchSize,seqLen,InputSize)\n",
    "inputs = torch.randn(batch_size, seq_len, input_size)  # (1,3,4)\n",
    "# Initializing the hidden to zero\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)  # (1,1,2)\n",
    "\n",
    "output, hidden = rnn(inputs, hidden)  # RNNå†…éƒ¨åŒ…å«äº†å¾ªç¯ï¼Œæ•…è¿™é‡Œåªéœ€æŠŠæ•´ä¸ªåºåˆ—è¾“å…¥å³å¯\n",
    "\n",
    "print('Output size:', output.shape)  # ä»…è¾“å‡ºç»´åº¦å‘ç”Ÿå˜åŒ–(batch_size, seq_len, hidden_size)\n",
    "print('Output:', output)\n",
    "print('Hidden size:', hidden.shape)  # (num_layers, batch_size, hidden_size)\n",
    "print('Hidden:', hidden)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 ä¾‹å­ï¼šåºåˆ—å˜æ¢æŠŠ \"hello\" --> \"ohlol\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 ä½¿ç”¨RNNCell"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:hehee, Epoch [1/15] loss: 8.2711\n",
      "Predicted string:olhll, Epoch [2/15] loss: 6.2931\n",
      "Predicted string:ollll, Epoch [3/15] loss: 5.3395\n",
      "Predicted string:ollll, Epoch [4/15] loss: 4.7223\n",
      "Predicted string:ohlll, Epoch [5/15] loss: 4.2614\n",
      "Predicted string:ohlll, Epoch [6/15] loss: 3.9137\n",
      "Predicted string:ohlol, Epoch [7/15] loss: 3.6579\n",
      "Predicted string:ohlol, Epoch [8/15] loss: 3.4601\n",
      "Predicted string:ohlol, Epoch [9/15] loss: 3.2896\n",
      "Predicted string:ohlol, Epoch [10/15] loss: 3.1306\n",
      "Predicted string:ohlol, Epoch [11/15] loss: 2.9806\n",
      "Predicted string:ohlol, Epoch [12/15] loss: 2.8476\n",
      "Predicted string:ohlol, Epoch [13/15] loss: 2.7450\n",
      "Predicted string:ohlol, Epoch [14/15] loss: 2.6792\n",
      "Predicted string:ohlol, Epoch [15/15] loss: 2.6347\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1ã€ç¡®å®šå‚æ•°\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "# 2ã€å‡†å¤‡æ•°æ®\n",
    "index2char = ['e', 'h', 'l', 'o']  #å­—å…¸\n",
    "x_data = [1, 0, 2, 2, 3]  #ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello\n",
    "y_data = [3, 1, 2, 3, 2]  #æ ‡ç­¾ï¼šohlol\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],  # ç”¨æ¥å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡çš„å‚ç…§è¡¨\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]  #å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)  #(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’,ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’Šğ’ğ’‘ğ’–ğ’•ğ‘ºğ’Šğ’›ğ’†)\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)  # (ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’,ğŸ).è®¡ç®—äº¤å‰ç†µæŸå¤±æ—¶æ ‡ç­¾ä¸éœ€è¦æˆ‘ä»¬è¿›è¡Œone-hotç¼–ç ï¼Œå…¶å†…éƒ¨ä¼šè‡ªåŠ¨è¿›è¡Œå¤„ç†\n",
    "\n",
    "\n",
    "# 3ã€æ„å»ºæ¨¡å‹\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnncell(input, hidden)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self):  #åˆå§‹åŒ–éšè—å±‚ï¼Œéœ€è¦batch_size\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)  # Adamä¼˜åŒ–å™¨\n",
    "\n",
    "# 5ã€è®­ç»ƒ\n",
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()  #æ¢¯åº¦æ¸…é›¶\n",
    "    hidden = net.init_hidden()  # åˆå§‹åŒ–éšè—å±‚\n",
    "    print('Predicted string:', end='')\n",
    "    for input, label in zip(inputs, labels):  #æ¯æ¬¡è¾“å…¥ä¸€ä¸ªå­—ç¬¦ï¼Œå³æŒ‰åºåˆ—æ¬¡åºè¿›è¡Œå¾ªç¯\n",
    "        hidden = net(input, hidden)\n",
    "        loss += criterion(hidden, label)  # è®¡ç®—æŸå¤±ï¼Œä¸ç”¨item()ï¼Œå› ä¸ºåé¢è¿˜è¦åå‘ä¼ æ’­\n",
    "        _, idx = hidden.max(dim=1)  # é€‰å–æœ€å¤§å€¼çš„ç´¢å¼•\n",
    "        print(index2char[idx.item()], end='')  # æ‰“å°é¢„æµ‹çš„å­—ç¬¦\n",
    "    loss.backward()  # åå‘ä¼ æ’­\n",
    "    optimizer.step()  # æ›´æ–°å‚æ•°\n",
    "    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 ä½¿ç”¨RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:  hhhhh, Epoch [1/15] loss: 1.4325\n",
      "Predicted string:  hhhhh, Epoch [2/15] loss: 1.2532\n",
      "Predicted string:  ohhoh, Epoch [3/15] loss: 1.1057\n",
      "Predicted string:  ohlol, Epoch [4/15] loss: 0.9970\n",
      "Predicted string:  ohlol, Epoch [5/15] loss: 0.9208\n",
      "Predicted string:  oolol, Epoch [6/15] loss: 0.8669\n",
      "Predicted string:  oolol, Epoch [7/15] loss: 0.8250\n",
      "Predicted string:  oolol, Epoch [8/15] loss: 0.7863\n",
      "Predicted string:  oolol, Epoch [9/15] loss: 0.7453\n",
      "Predicted string:  oolol, Epoch [10/15] loss: 0.7024\n",
      "Predicted string:  oolol, Epoch [11/15] loss: 0.6625\n",
      "Predicted string:  oolol, Epoch [12/15] loss: 0.6291\n",
      "Predicted string:  ohlol, Epoch [13/15] loss: 0.6026\n",
      "Predicted string:  ohlol, Epoch [14/15] loss: 0.5812\n",
      "Predicted string:  ohlol, Epoch [15/15] loss: 0.5630\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1ã€ç¡®å®šå‚æ•°\n",
    "seq_len = 5\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "# 2ã€å‡†å¤‡æ•°æ®\n",
    "index2char = ['e', 'h', 'l', 'o']  #å­—å…¸\n",
    "x_data = [1, 0, 2, 2, 3]  #ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello\n",
    "y_data = [3, 1, 2, 3, 2]  #æ ‡ç­¾ï¼šohlol\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0],  # ç”¨æ¥å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡çš„å‚ç…§è¡¨\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]  #å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size,\n",
    "                                      input_size)  #(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’,ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’Šğ’ğ’‘ğ’–ğ’•ğ‘ºğ’Šğ’›ğ’†)\n",
    "labels = torch.LongTensor(y_data)\n",
    "\n",
    "\n",
    "# 3ã€æ„å»ºæ¨¡å‹\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        out, _ = self.rnn(input, hidden)  # out: tensor of shape (seq_len, batch, hidden_size)\n",
    "        return out.view(-1, self.hidden_size)  # å°†è¾“å‡ºçš„ä¸‰ç»´å¼ é‡è½¬æ¢ä¸ºäºŒç»´å¼ é‡,(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’Ã—ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’‰ğ’Šğ’…ğ’…ğ’†ğ’ğ‘ºğ’Šğ’›ğ’†)\n",
    "\n",
    "    def init_hidden(self):  #åˆå§‹åŒ–éšè—å±‚ï¼Œéœ€è¦batch_size\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "\n",
    "\n",
    "net = Model(input_size, hidden_size, batch_size, num_layers)\n",
    "\n",
    "# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)  # Adamä¼˜åŒ–å™¨\n",
    "\n",
    "# 5ã€è®­ç»ƒ\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted string: ', ''.join([index2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 ä½¿ç”¨embedding and linear layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:  eeeee, Epoch [1/15] loss: 1.5407\n",
      "Predicted string:  oolol, Epoch [2/15] loss: 1.1158\n",
      "Predicted string:  oolol, Epoch [3/15] loss: 0.9047\n",
      "Predicted string:  ohlol, Epoch [4/15] loss: 0.7391\n",
      "Predicted string:  lhlol, Epoch [5/15] loss: 0.6006\n",
      "Predicted string:  ohlol, Epoch [6/15] loss: 0.4833\n",
      "Predicted string:  ohlol, Epoch [7/15] loss: 0.3581\n",
      "Predicted string:  ohlol, Epoch [8/15] loss: 0.2540\n",
      "Predicted string:  ohlol, Epoch [9/15] loss: 0.1921\n",
      "Predicted string:  ohlol, Epoch [10/15] loss: 0.1351\n",
      "Predicted string:  ohlol, Epoch [11/15] loss: 0.0972\n",
      "Predicted string:  ohlol, Epoch [12/15] loss: 0.0752\n",
      "Predicted string:  ohlol, Epoch [13/15] loss: 0.0594\n",
      "Predicted string:  ohlol, Epoch [14/15] loss: 0.0465\n",
      "Predicted string:  ohlol, Epoch [15/15] loss: 0.0363\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1ã€ç¡®å®šå‚æ•°\n",
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "# 2ã€å‡†å¤‡æ•°æ®\n",
    "index2char = ['e', 'h', 'l', 'o']  #å­—å…¸\n",
    "x_data = [[1, 0, 2, 2, 3]]  # (batch_size, seq_len) ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello\n",
    "y_data = [3, 1, 2, 3, 2]  #  (batch_size * seq_len) æ ‡ç­¾ï¼šohlol\n",
    "\n",
    "inputs = torch.LongTensor(x_data)  # (batch_size, seq_len)\n",
    "labels = torch.LongTensor(y_data)  # (batch_size * seq_len)\n",
    "\n",
    "\n",
    "# 3ã€æ„å»ºæ¨¡å‹\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(num_class, embedding_size)\n",
    "        self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                                batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)  # (num_layers, batch_size, hidden_size)\n",
    "        x = self.emb(x)  # è¿”å›(batch_size, seq_len, embedding_size)\n",
    "        x, _ = self.rnn(x, hidden)  # è¿”å›(batch_size, seq_len, hidden_size)\n",
    "        x = self.fc(x)  # è¿”å›(batch_size, seq_len, num_class)\n",
    "        return x.view(-1, num_class)  # (batch_size * seq_len, num_class)\n",
    "\n",
    "\n",
    "net = Model()\n",
    "\n",
    "# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)  # Adamä¼˜åŒ–å™¨\n",
    "\n",
    "# 5ã€è®­ç»ƒ\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted string: ', ''.join([index2char[x] for x in idx]), end='')\n",
    "    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}