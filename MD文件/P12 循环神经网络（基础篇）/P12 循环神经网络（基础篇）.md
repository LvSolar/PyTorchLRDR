[TOC]

# 1 ä»€ä¹ˆæ˜¯RNNï¼Ÿ

RNNæ˜¯å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRecurrent Neural Networkï¼‰çš„ç¼©å†™ã€‚å®ƒæ˜¯ä¸€ç§ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¯ä»¥å¤„ç†åºåˆ—æ•°æ®ï¼Œä¾‹å¦‚æ—¶é—´åºåˆ—æ•°æ®æˆ–è‡ªç„¶è¯­è¨€æ–‡æœ¬æ•°æ®ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„å‰é¦ˆç¥ç»ç½‘ç»œï¼ŒRNNå¯ä»¥åˆ©ç”¨å½“å‰çš„è¾“å…¥å’Œä¹‹å‰çš„çŠ¶æ€æ¥å†³å®šå½“å‰çš„è¾“å‡ºï¼Œå› æ­¤å®ƒå¯ä»¥æ•æ‰åˆ°åºåˆ—æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚

åœ¨RNNä¸­ï¼Œæ¯ä¸ªæ—¶é—´æ­¥éƒ½æœ‰ä¸€ä¸ªéšè—çŠ¶æ€ï¼ˆhidden stateï¼‰ï¼Œè¿™ä¸ªéšè—çŠ¶æ€å¯ä»¥æ•æ‰åˆ°ä¹‹å‰æ—¶é—´æ­¥çš„ä¿¡æ¯ï¼Œå¹¶ä¸”ä¼šåœ¨å½“å‰æ—¶é—´æ­¥ä¸­è¢«ç”¨äºè®¡ç®—è¾“å‡ºã€‚RNNçš„è®­ç»ƒè¿‡ç¨‹é€šå¸¸ä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•å’Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æ¨¡å‹é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„è¯¯å·®ã€‚

**RNNåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ã€æ—¶é—´åºåˆ—é¢„æµ‹ç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›çš„åº”ç”¨**ã€‚

![image-20230423123352273](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231233367.png)

## 1.1 åŸç†

**RNNçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å½“å‰çš„è¾“å…¥å’Œä¹‹å‰çš„çŠ¶æ€æ¥å†³å®šå½“å‰çš„è¾“å‡ºï¼Œè¿™ä½¿å¾—RNNå¯ä»¥å¤„ç†åºåˆ—æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚**RNNçš„ç»“æ„å¯ä»¥çœ‹ä½œæ˜¯åœ¨æ—¶é—´è½´ä¸Šå±•å¼€çš„å¤šä¸ªç¥ç»ç½‘ç»œå±‚ï¼Œæ¯ä¸ªæ—¶é—´æ­¥éƒ½æœ‰ä¸€ä¸ªéšè—çŠ¶æ€ï¼Œè¿™ä¸ªéšè—çŠ¶æ€å¯ä»¥ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå¹¶å‚ä¸å½“å‰æ—¶é—´æ­¥çš„è®¡ç®—ã€‚

![image-20230423123912734](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231239817.png)

å…·ä½“æ¥è¯´ï¼ŒRNNçš„è®¡ç®—å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼š

1. **è¾“å…¥å±‚å’Œéšè—å±‚ä¹‹é—´çš„è®¡ç®—ã€‚**å‡è®¾å½“å‰æ—¶é—´æ­¥çš„è¾“å…¥æ˜¯$x_t$ï¼Œä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ˜¯$h_{t-1}$ï¼Œé‚£ä¹ˆå½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€$h_t$å¯ä»¥é€šè¿‡ä¸‹é¢çš„å…¬å¼è®¡ç®—å¾—åˆ°ï¼š

$$
h_t = f(W_{ih} x_t + b_{ih} + W_{hh} h_{t-1} + b_{hh})
$$

å…¶ä¸­$W_{ih}$æ˜¯è¾“å…¥å±‚åˆ°éšè—å±‚çš„æƒé‡çŸ©é˜µï¼Œ$W_{hh}$æ˜¯éšè—å±‚åˆ°éšè—å±‚çš„æƒé‡çŸ©é˜µï¼Œ$b_{ih}$å’Œ$b_{hh}$æ˜¯éšè—å±‚çš„åç½®å‘é‡ï¼Œ$f$æ˜¯æ¿€æ´»å‡½æ•°ï¼ˆé€šå¸¸æ˜¯tanhæˆ–ReLUï¼Œä¸Šå›¾ä¸­æ˜¯tanhï¼Œå³åŒæ›²æ­£åˆ‡å‡½æ•°ï¼‰ã€‚

2. **éšè—å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„è®¡ç®—ã€‚**å‡è®¾å½“å‰æ—¶é—´æ­¥çš„éšè—çŠ¶æ€æ˜¯$h_t$ï¼Œé‚£ä¹ˆå½“å‰æ—¶é—´æ­¥çš„è¾“å‡º$y_t$å¯ä»¥é€šè¿‡ä¸‹é¢çš„å…¬å¼è®¡ç®—å¾—åˆ°ï¼š

$$
y_t=g(W_{hy}h_t+b_y)
$$

å…¶ä¸­$W_{hy}$æ˜¯éšè—å±‚åˆ°è¾“å‡ºå±‚çš„æƒé‡çŸ©é˜µï¼Œ$b_y$æ˜¯è¾“å‡ºå±‚çš„åç½®å‘é‡ï¼Œ$g$æ˜¯è¾“å‡ºå±‚çš„æ¿€æ´»å‡½æ•°ï¼ˆé€šå¸¸æ˜¯softmaxï¼‰ã€‚

3. **æŸå¤±å‡½æ•°è®¡ç®—å’Œåå‘ä¼ æ’­ã€‚**æ ¹æ®ä»»åŠ¡ç±»å‹ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±å‡½æ•°ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œå‡æ–¹è¯¯å·®æŸå¤±å‡½æ•°ç”¨äºå›å½’ä»»åŠ¡ã€‚ç„¶åä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•å’Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•æ¥æ›´æ–°æƒé‡å’Œåç½®ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æ¨¡å‹é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„è¯¯å·®ã€‚

RNNçš„ä¸»è¦ä¼˜ç‚¹æ˜¯å¯ä»¥å¤„ç†ä»»æ„é•¿åº¦çš„åºåˆ—æ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥æ•æ‰åºåˆ—æ•°æ®ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»ã€‚ç„¶è€Œï¼ŒRNNä¹Ÿå­˜åœ¨ä¸€äº›ç¼ºç‚¹ï¼Œä¾‹å¦‚**éš¾ä»¥å¤„ç†é•¿æœŸä¾èµ–å…³ç³»ã€è®­ç»ƒé€Ÿåº¦æ…¢ã€æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ç­‰é—®é¢˜**ã€‚å› æ­¤ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†è®¸å¤šæ”¹è¿›çš„RNNæ¨¡å‹ï¼Œä¾‹å¦‚LSTMå’ŒGRUç­‰ã€‚

## 1.2 ç»´åº¦è¯´æ˜

åœ¨RNNä¸­ï¼Œè¾“å…¥ã€è¾“å‡ºå’Œéšè—å±‚çš„ç»´åº¦å¯ä»¥æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯å’Œæ•°æ®é›†æ¥ç¡®å®šã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦æ˜¯å›ºå®šçš„ï¼Œè€Œéšè—å±‚çš„ç»´åº¦åˆ™æ˜¯ç”±ç”¨æˆ·è‡ªå·±æŒ‡å®šçš„è¶…å‚æ•°ã€‚

ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„ç»´åº¦é…ç½®ï¼š

1. åºåˆ—åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¾“å…¥é€šå¸¸æ˜¯ä¸€ä¸ªåºåˆ—çš„ç‰¹å¾å‘é‡ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªç±»åˆ«æ ‡ç­¾ã€‚å‡è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸º`seq_len`ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º`input_size`ï¼Œè¾“å‡ºç±»åˆ«æ•°ä¸º`num_classes`ï¼Œé‚£ä¹ˆè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦åˆ†åˆ«ä¸º`[batch_size, seq_len, input_size]`å’Œ`[batch_size, num_classes]`ï¼Œå…¶ä¸­`batch_size`ä¸ºæ‰¹æ¬¡å¤§å°ã€‚
2. åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯ä¸€ä¸ªåºåˆ—ã€‚å‡è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸º`seq_len`ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º`input_size`ï¼Œè¾“å‡ºåºåˆ—çš„é•¿åº¦ä¹Ÿä¸º`seq_len`ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º`output_size`ï¼Œé‚£ä¹ˆè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦éƒ½ä¸º`[batch_size, seq_len, input_size]`æˆ–`[batch_size, seq_len, output_size]`ï¼Œå…·ä½“è¦çœ‹æ˜¯ä»€ä¹ˆä»»åŠ¡ã€‚
3. åºåˆ—æ ‡æ³¨ä»»åŠ¡ä¸­ï¼Œè¾“å…¥é€šå¸¸æ˜¯ä¸€ä¸ªåºåˆ—çš„ç‰¹å¾å‘é‡ï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªæ—¶é—´æ­¥çš„æ ‡æ³¨ä¿¡æ¯ã€‚å‡è®¾è¾“å…¥åºåˆ—çš„é•¿åº¦ä¸º`seq_len`ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡ç»´åº¦ä¸º`input_size`ï¼Œè¾“å‡ºæ ‡æ³¨ç±»åˆ«æ•°ä¸º`num_classes`ï¼Œé‚£ä¹ˆè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦åˆ†åˆ«ä¸º`[batch_size, seq_len, input_size]`å’Œ`[batch_size, seq_len, num_classes]`ã€‚
4. åœ¨éšè—å±‚ç»´åº¦æ–¹é¢ï¼Œå¯ä»¥æ ¹æ®ä»»åŠ¡å’Œæ•°æ®é›†çš„å¤æ‚ç¨‹åº¦æ¥é€‰æ‹©åˆé€‚çš„å€¼ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œéšè—å±‚çš„ç»´åº¦è¶Šå¤§ï¼Œæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å°±è¶Šå¼ºï¼Œä½†ä¹Ÿä¼šå¢åŠ æ¨¡å‹çš„è®¡ç®—å¤æ‚åº¦å’Œè®­ç»ƒéš¾åº¦ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œéšè—å±‚çš„ç»´åº¦åœ¨å‡ ååˆ°å‡ ç™¾ä¹‹é—´ã€‚

# 2 ä¸€äº›çç¢ä»£ç 

## 2.1 RNNCell

![image-20230423130301157](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231303247.png)

è¿™æ®µä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨PyTorchçš„**RNNCell**æ¨¡å—æ„å»ºä¸€ä¸ªç®€å•çš„RNNï¼Œå¹¶å¯¹ä¸€ä¸ªç®€å•çš„åºåˆ—è¿›è¡Œå‰å‘ä¼ é€’è®¡ç®—ã€‚

åœ¨ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªRNNCellå¯¹è±¡ï¼Œä½¿ç”¨äº†è¾“å…¥ç»´åº¦ä¸ºinput_sizeã€è¾“å‡ºç»´åº¦ä¸ºhidden_sizeçš„éšè—å±‚ã€‚æ¥ç€ï¼Œæˆ‘ä»¬æ„é€ äº†ä¸€ä¸ªå¤§å°ä¸º(seq_len, batch_size, input_size)çš„è¾“å…¥æ•°æ®é›†datasetï¼Œå¹¶å°†éšè—çŠ¶æ€hiddenåˆå§‹åŒ–ä¸ºå…¨é›¶å¼ é‡ï¼Œå¤§å°ä¸º(batch_size, hidden_size)ã€‚

ç„¶åï¼Œæˆ‘ä»¬å°†æ•°æ®é›†æŒ‰åºåˆ—é•¿åº¦ä¾æ¬¡è¾“å…¥åˆ°RNNCellä¸­ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥æ›´æ–°éšè—çŠ¶æ€hiddenã€‚åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬æ‰“å°å‡ºéšè—çŠ¶æ€hiddençš„å½¢çŠ¶å’Œå€¼ï¼Œä»¥ä¾¿äº†è§£RNNåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºæƒ…å†µã€‚

==å…·ä½“æ¥è¯´ï¼Œå¾ªç¯ä»seq_lençš„ç¬¬0ä¸ªæ—¶é—´æ­¥å¼€å§‹ï¼Œä¾æ¬¡å°†å¤§å°ä¸º(batch_size, input_size)çš„è¾“å…¥æ•°æ®inputè¾“å…¥åˆ°RNNCellä¸­ï¼Œå¹¶ç”¨å½“å‰çš„éšè—çŠ¶æ€hiddenè®¡ç®—ä¸‹ä¸€ä¸ªéšè—çŠ¶æ€==ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªç®€å•çš„å¾ªç¯ï¼Œæ¯æ¬¡æ›´æ–°éšè—çŠ¶æ€æ—¶ï¼Œè¾“å‡ºçš„hiddenå¤§å°ä¿æŒä¸å˜ï¼Œéƒ½æ˜¯(batch_size, hidden_size)ã€‚

**ä»£ç å¦‚ä¸‹ï¼š**


```python
import torch

batch_size = 1
seq_len = 3
input_size = 4
hidden_size = 2

# Construction of RNNCell
cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)
# Wrapping the sequence into:(seqLen,batchSize,InputSize)
dataset = torch.randn(seq_len, batch_size, input_size)  # (3,1,4)
# Initializing the hidden to zero
hidden = torch.zeros(batch_size, hidden_size)  # (1,2)

for idx, input in enumerate(dataset):
    print('=' * 20, idx, '=' * 20)  #åˆ†å‰²çº¿ï¼Œ20ä¸ª=å·
    print('Input size:', input.shape)  # (batch_size, input_size)
    # æŒ‰åºåˆ—ä¾æ¬¡è¾“å…¥åˆ°cellä¸­ï¼Œseq_len=3ï¼Œæ•…å¾ªç¯3æ¬¡
    hidden = cell(input, hidden)  # è¿”å›çš„hiddenæ˜¯ä¸‹ä¸€æ¬¡çš„è¾“å…¥ä¹‹ä¸€ï¼Œå¾ªç¯ä½¿ç”¨åŒä¸€ä¸ªcell

    print('output size:', hidden.shape)  # (batch_size, hidden_size)
    print(hidden)
```

**è¿è¡Œç»“æœï¼š**

    ==================== 0 ====================
    Input size: torch.Size([1, 4])
    output size: torch.Size([1, 2])
    tensor([[-0.4140,  0.1517]], grad_fn=<TanhBackward0>)
    ==================== 1 ====================
    Input size: torch.Size([1, 4])
    output size: torch.Size([1, 2])
    tensor([[-0.4725, -0.7875]], grad_fn=<TanhBackward0>)
    ==================== 2 ====================
    Input size: torch.Size([1, 4])
    output size: torch.Size([1, 2])
    tensor([[-0.8257, -0.2262]], grad_fn=<TanhBackward0>)

å¯ä»¥çœ‹åˆ°ï¼Œæ¯æ¬¡è®¡ç®—åçš„éšè—çŠ¶æ€hiddenéƒ½æ˜¯2ç»´çš„å¼ é‡ï¼Œå¤§å°ä¸º(batch_size, hidden_size) = (1, 2)ã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ä¸­ï¼Œè¾“å‡ºçš„hiddenå€¼éƒ½ä¸åŒï¼Œå› ä¸ºè¾“å…¥æ•°æ®é›†datasetä¸åŒï¼Œè€Œéšè—çŠ¶æ€hiddenæ˜¯éšç€æ—¶é—´æ­¥éª¤çš„æ¨è¿›è€Œæ›´æ–°çš„ã€‚

## 2.2 RNN

![image-20230423130925511](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231309603.png)

![image-20230423132517785](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231325876.png)

è¿™æ®µä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨PyTorchçš„**RNNæ¨¡å—**æ„å»ºä¸€ä¸ªç®€å•çš„RNNï¼Œå¹¶å¯¹ä¸€ä¸ªç®€å•çš„åºåˆ—è¿›è¡Œå‰å‘ä¼ é€’è®¡ç®—ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªRNNå¯¹è±¡ï¼Œä½¿ç”¨äº†è¾“å…¥ç»´åº¦ä¸ºinput_sizeã€è¾“å‡ºç»´åº¦ä¸ºhidden_sizeçš„éšè—å±‚ï¼Œå¹¶è®¾ç½®äº†RNNçš„å±‚æ•°num_layersä¸º1ï¼ˆä¸Šå›¾æ˜¯num_layersä¸º3çš„åŸç†å›¾ï¼Œæˆ‘ä»¬è¿™é‡Œåªä½¿ç”¨äº†1å±‚RNNï¼‰ã€‚æ¥ç€ï¼Œæˆ‘ä»¬æ„é€ äº†ä¸€ä¸ªå¤§å°ä¸º(seq_len, batch_size, input_size)çš„è¾“å…¥æ•°æ®inputsï¼Œå¹¶å°†éšè—çŠ¶æ€hiddenåˆå§‹åŒ–ä¸ºå…¨é›¶å¼ é‡ï¼Œå¤§å°ä¸º(num_layers, batch_size, hidden_size)ã€‚

==ç„¶åï¼Œæˆ‘ä»¬**å°†æ•´ä¸ªè¾“å…¥åºåˆ—inputsè¾“å…¥åˆ°RNNä¸­å¹¶å¾—åˆ°è¾“å‡ºoutputå’Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€hidden**ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç”±äºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªRNNå±‚ï¼Œå› æ­¤hiddençš„å¤§å°ä¸åˆå§‹å¤§å°ç›¸åŒï¼Œä»…ä»…æ˜¯åœ¨ç¬¬ä¸€ç»´ä¸Šæ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç»´åº¦ã€‚==

æœ€åï¼Œæˆ‘ä»¬æ‰“å°è¾“å‡ºoutputå’Œéšè—çŠ¶æ€hiddençš„å½¢çŠ¶å’Œå€¼ï¼Œä»¥ä¾¿äº†è§£RNNåœ¨æ•´ä¸ªåºåˆ—ä¸Šçš„è¾“å‡ºæƒ…å†µã€‚

å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ•´ä¸ªè¾“å…¥åºåˆ—çš„è¾“å‡ºoutputæ˜¯ä¸€ä¸ªå¤§å°ä¸º(seq_len, batch_size, hidden_size) = (3, 1, 2)çš„å¼ é‡ã€‚å…¶ä¸­ï¼Œç¬¬ä¸€ç»´è¡¨ç¤ºåºåˆ—é•¿åº¦ï¼Œç¬¬äºŒç»´è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼Œç¬¬ä¸‰ç»´è¡¨ç¤ºéšè—å±‚è¾“å‡ºçš„ç»´åº¦ã€‚è€Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€hiddenæ˜¯ä¸€ä¸ªå¤§å°ä¸º(num_layers, batch_size, hidden_size) = (1, 1, 2)çš„å¼ é‡ã€‚å…¶ä¸­ï¼Œç¬¬ä¸€ç»´è¡¨ç¤ºRNNçš„å±‚æ•°ï¼Œç¬¬äºŒç»´è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼Œç¬¬ä¸‰ç»´è¡¨ç¤ºéšè—å±‚è¾“å‡ºçš„ç»´åº¦ã€‚

**ä»£ç å¦‚ä¸‹ï¼š**


```python
import torch

batch_size = 1
seq_len = 3
input_size = 4
hidden_size = 2
num_layers = 1  # RNNå±‚æ•°

# Construction of RNN
rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)
# Wrapping the sequence into:(seqLen,batchSize,InputSize)
inputs = torch.randn(seq_len, batch_size, input_size)  # (3,1,4)
# Initializing the hidden to zero
hidden = torch.zeros(num_layers, batch_size, hidden_size)  # (1,1,2)

output, hidden = rnn(inputs, hidden)  # RNNå†…éƒ¨åŒ…å«äº†å¾ªç¯ï¼Œæ•…è¿™é‡Œåªéœ€æŠŠæ•´ä¸ªåºåˆ—è¾“å…¥å³å¯

print('Output size:', output.shape)  # (seq_len, batch_size, hidden_size)
print('Output:', output)
print('Hidden size:', hidden.shape)  # (num_layers, batch_size, hidden_size)
print('Hidden:', hidden)
```

**è¿è¡Œç»“æœï¼š**

    Output size: torch.Size([3, 1, 2])
    Output: tensor([[[-0.9880, -0.8818]],
    
            [[ 0.6066,  0.9090]],
    
            [[-0.3108,  0.7957]]], grad_fn=<StackBackward0>)
    Hidden size: torch.Size([1, 1, 2])
    Hidden: tensor([[[-0.3108,  0.7957]]], grad_fn=<StackBackward0>)

å¯ä»¥çœ‹åˆ°ï¼Œè¾“å‡ºoutputæ˜¯ä¸€ä¸ª3ç»´çš„å¼ é‡ï¼Œå¤§å°ä¸º(seq_len, batch_size, hidden_size) = (3, 1, 2)ï¼Œåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºå€¼éƒ½ä¸åŒã€‚æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€hiddenæ˜¯ä¸€ä¸ª3ç»´çš„å¼ é‡ï¼Œå¤§å°ä¸º(num_layers, batch_size, hidden_size) = (1, 1, 2)ï¼Œæ˜¯æ•´ä¸ªåºåˆ—çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚

==**è¿™ä¸ªè·Ÿä¹‹å‰çš„RNNCellæœ‰ä»€ä¹ˆä¸åŒå‘¢ï¼Ÿ**==

å‰é¢çš„ä¾‹å­ä¸­ä½¿ç”¨äº†**RNNCellï¼Œå®ƒåªæ˜¯RNNçš„ä¸€ä¸ªå•å…ƒï¼Œç”¨äºå¤„ç†ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥æ•°æ®ï¼Œéœ€è¦åœ¨å¾ªç¯ä¸­æ‰‹åŠ¨å¤„ç†æ—¶é—´æ­¥**ã€‚è€Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†**å®Œæ•´çš„RNNæ¨¡å‹ï¼Œå®ƒå†…éƒ¨åŒ…å«äº†å¾ªç¯ç»“æ„ï¼Œå¯ä»¥ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªåºåˆ—çš„è¾“å…¥ï¼Œä»è€Œé¿å…äº†æ‰‹åŠ¨å¤„ç†æ—¶é—´æ­¥çš„ç¹çè¿‡ç¨‹**ã€‚

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨torch.nn.RNNæ„é€ äº†ä¸€ä¸ªRNNæ¨¡å‹ï¼Œå¹¶å°†æ•´ä¸ªåºåˆ—inputsè¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Œæ¨¡å‹å†…éƒ¨å®Œæˆäº†æ‰€æœ‰çš„å¾ªç¯è®¡ç®—ï¼Œå¹¶è¿”å›äº†æ•´ä¸ªåºåˆ—çš„è¾“å‡ºoutputå’Œæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€hiddenã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ¨¡å‹ä¸­çš„hiddençŠ¶æ€æ˜¯åœ¨ä¸åŒçš„æ—¶é—´æ­¥å…±äº«çš„ï¼Œå³å½“å‰æ—¶é—´æ­¥çš„éšçŠ¶æ€hiddenæ˜¯ç”±ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºå’ŒéšçŠ¶æ€è®¡ç®—å¾—åˆ°çš„ï¼Œè¿™ä¸å‰é¢çš„RNNCellæ˜¯ç±»ä¼¼çš„ã€‚ä½†æ˜¯ï¼Œå®Œæ•´çš„RNNæ¨¡å‹ä¼šè‡ªåŠ¨å®Œæˆæ—¶é—´æ­¥ä¹‹é—´çš„å¾ªç¯ï¼Œå› æ­¤æ›´åŠ æ–¹ä¾¿ã€‚

## 2.3 RNNå‚æ•°ï¼šbatch_first

åœ¨PyTorchä¸­ï¼ŒRNNæ¨¡å‹çš„è¾“å…¥é€šå¸¸æ˜¯(seq_len, batch_size, input_size)è¿™æ ·çš„å½¢å¼ï¼Œå³æ—¶é—´æ­¥åºåˆ—æ’åˆ—åœ¨ç¬¬ä¸€ç»´ï¼Œæ‰¹é‡æ•°æ®æ’åˆ—åœ¨ç¬¬äºŒç»´ã€‚ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½æ›´å€¾å‘äºä½¿ç”¨(batch_size, seq_len, input_size)çš„è¾“å…¥å½¢å¼ã€‚ä¸ºäº†æ»¡è¶³è¿™ç§éœ€è¦ï¼ŒPyTorchæä¾›äº†batch_firstå‚æ•°ã€‚

å½“batch_first=Trueæ—¶ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„å½¢çŠ¶å°±å˜æˆäº†(batch_size, seq_len, input_size)ï¼Œè¿™æ ·å°±æ›´ç¬¦åˆä¸€èˆ¬çš„æ•°æ®æ ¼å¼ã€‚åœ¨æ„é€ RNNæ¨¡å‹æ—¶ï¼Œåªéœ€å°†batch_firstå‚æ•°è®¾ç½®ä¸ºTrueå³å¯ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ªRNNæ¨¡å‹ï¼Œå½“batch_first=Falseæ—¶ï¼Œè¾“å…¥çš„å½¢çŠ¶ä¸º(seq_len, batch_size, input_size)ï¼Œè€Œ**å½“batch_first=Trueæ—¶ï¼Œè¾“å…¥çš„å½¢çŠ¶ä¸º(batch_size, seq_len, input_size)**ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š


```python
import torch

batch_size = 1
seq_len = 3
input_size = 4
hidden_size = 2
num_layers = 1  # RNNå±‚æ•°

# Construction of RNN, batch_first=True
rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)
# ä»…è¿™é‡Œåšäº†æ›´æ”¹ Wrapping the sequence into:(batchSize,seqLen,InputSize)
inputs = torch.randn(batch_size, seq_len, input_size)  # (1,3,4)
# Initializing the hidden to zero
hidden = torch.zeros(num_layers, batch_size, hidden_size)  # (1,1,2)

output, hidden = rnn(inputs, hidden)  # RNNå†…éƒ¨åŒ…å«äº†å¾ªç¯ï¼Œæ•…è¿™é‡Œåªéœ€æŠŠæ•´ä¸ªåºåˆ—è¾“å…¥å³å¯

print('Output size:', output.shape)  # è¾“å‡ºç»´åº¦å‘ç”Ÿå˜åŒ–(batch_size, seq_len, hidden_size)
print('Output:', output)
print('Hidden size:', hidden.shape)  # (num_layers, batch_size, hidden_size)
print('Hidden:', hidden)
```

    Output size: torch.Size([1, 3, 2])
    Output: tensor([[[ 0.6276, -0.1454],
             [ 0.0294,  0.3148],
             [-0.3239,  0.4692]]], grad_fn=<TransposeBackward1>)
    Hidden size: torch.Size([1, 1, 2])
    Hidden: tensor([[[-0.3239,  0.4692]]], grad_fn=<StackBackward0>)

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªRNNæ¨¡å‹ï¼Œå°†batch_firstå‚æ•°è®¾ç½®ä¸ºTrueï¼Œå¹¶å°†è¾“å…¥æ•°æ®inputsçš„å½¢çŠ¶è®¾ç½®ä¸º(batch_size, seq_len, input_size)ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ–¹ä¾¿åœ°å¤„ç†è¾“å…¥æ•°æ®ï¼Œè€Œä¸ç”¨æ‹…å¿ƒæ—¶é—´æ­¥å’Œæ‰¹é‡ä¹‹é—´çš„é¡ºåºé—®é¢˜ã€‚

# 3 ä¾‹å­ï¼šåºåˆ—å˜æ¢æŠŠ "hello" --> "ohlol"

![image-20230423133037919](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231330021.png)

## 3.1 ä½¿ç”¨RNNCell

**è¾“å…¥çš„ç‹¬çƒ­ç¼–ç ç¤ºæ„å›¾ï¼š**

![image-20230423133230333](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231332417.png)

**è¾“å‡ºç¤ºæ„å›¾ï¼š**

![image-20230423133401053](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231334136.png)

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªåŸºäºRNNCellçš„ç®€å•çš„å­—ç¬¦çº§åˆ«çš„è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚å…·ä½“çš„è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š

1. å®šä¹‰äº†ä¸€ä¸ªå¤§å°ä¸º`input_size`çš„è¾“å…¥å‘é‡ï¼Œå¤§å°ä¸º`hidden_size`çš„éšè—å‘é‡å’Œæ‰¹æ¬¡å¤§å°ä¸º`batch_size`çš„`Model`ç±»ï¼Œå¹¶ä¸”åœ¨è¿™ä¸ªç±»çš„åˆå§‹åŒ–å‡½æ•°ä¸­ï¼Œæ„å»ºäº†ä¸€ä¸ª`RNNCell`ã€‚
2. ä½¿ç”¨ç»™å®šçš„ç´¢å¼•ï¼Œå°†è¾“å…¥åºåˆ—è½¬æ¢ä¸º one-hot å‘é‡ï¼Œå¹¶å°†è¾“å…¥åºåˆ—å’Œæ ‡ç­¾åºåˆ—éƒ½è¿›è¡Œç»´åº¦å˜æ¢ï¼Œä½¿å…¶å˜ä¸º `(sequence_length, batch_size, input_size)` å’Œ `(sequence_length, 1)`ã€‚
3. å®šä¹‰æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨ä¸º Adamã€‚
4. åœ¨å¾ªç¯è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡è¾“å…¥ä¸€ä¸ªå­—ç¬¦ï¼Œå³æŒ‰åºåˆ—æ¬¡åºè¿›è¡Œå¾ªç¯ã€‚æ¯æ¬¡è®­ç»ƒå‰å…ˆå°†ä¼˜åŒ–å™¨çš„æ¢¯åº¦æ¸…é›¶ï¼Œç„¶åä½¿ç”¨ `net.init_hidden()` åˆå§‹åŒ–éšè—å±‚ï¼Œå¹¶åœ¨å¾ªç¯ä¸­ä½¿ç”¨ `net(input, hidden)` å¾—åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ã€‚æ¥ç€è®¡ç®—æŸå¤±ï¼Œè¿›è¡Œåå‘ä¼ æ’­ï¼Œæ›´æ–°å‚æ•°ã€‚æ¯æ¬¡å¾ªç¯ä¸­è¿˜ä¼šæ‰“å°å‡ºé¢„æµ‹çš„å­—ç¬¦å’Œå½“å‰æŸå¤±ã€‚
5. å¾ªç¯è®­ç»ƒ15æ¬¡ï¼Œç›´åˆ°è®­ç»ƒå®Œæˆã€‚


```python
import torch

# 1ã€ç¡®å®šå‚æ•°
input_size = 4
hidden_size = 4
batch_size = 1

# 2ã€å‡†å¤‡æ•°æ®
index2char = ['e', 'h', 'l', 'o']  #å­—å…¸
x_data = [1, 0, 2, 2, 3]  #ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello
y_data = [3, 1, 2, 3, 2]  #æ ‡ç­¾ï¼šohlol

one_hot_lookup = [[1, 0, 0, 0],  # ç”¨æ¥å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡çš„å‚ç…§è¡¨
                  [0, 1, 0, 0],
                  [0, 0, 1, 0],
                  [0, 0, 0, 1]]
x_one_hot = [one_hot_lookup[x] for x in x_data]  #å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡
inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)  #(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’,ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’Šğ’ğ’‘ğ’–ğ’•ğ‘ºğ’Šğ’›ğ’†)
labels = torch.LongTensor(y_data).view(-1, 1)  # (seqLen*batchSize,ğŸ).è®¡ç®—äº¤å‰ç†µæŸå¤±æ—¶æ ‡ç­¾ä¸éœ€è¦æˆ‘ä»¬è¿›è¡Œone-hotç¼–ç ï¼Œå…¶å†…éƒ¨ä¼šè‡ªåŠ¨è¿›è¡Œå¤„ç†


# 3ã€æ„å»ºæ¨¡å‹
class Model(torch.nn.Module):
    def __init__(self, input_size, hidden_size, batch_size):
        super(Model, self).__init__()
        self.batch_size = batch_size
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)

    def forward(self, input, hidden):
        hidden = self.rnncell(input, hidden)
        return hidden

    def init_hidden(self):  #åˆå§‹åŒ–éšè—å±‚ï¼Œéœ€è¦batch_size
        return torch.zeros(self.batch_size, self.hidden_size)


net = Model(input_size, hidden_size, batch_size)

# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=0.1)  # Adamä¼˜åŒ–å™¨

# 5ã€è®­ç»ƒ
for epoch in range(15):
    loss = 0
    optimizer.zero_grad()  #æ¢¯åº¦æ¸…é›¶
    hidden = net.init_hidden()  # åˆå§‹åŒ–éšè—å±‚
    print('Predicted string:', end='')
    for input, label in zip(inputs, labels):  #æ¯æ¬¡è¾“å…¥ä¸€ä¸ªå­—ç¬¦ï¼Œå³æŒ‰åºåˆ—æ¬¡åºè¿›è¡Œå¾ªç¯
        hidden = net(input, hidden)
        loss += criterion(hidden, label)  # è®¡ç®—æŸå¤±ï¼Œä¸ç”¨item()ï¼Œå› ä¸ºåé¢è¿˜è¦åå‘ä¼ æ’­
        _, idx = hidden.max(dim=1)  # é€‰å–æœ€å¤§å€¼çš„ç´¢å¼•
        print(index2char[idx.item()], end='')  # æ‰“å°é¢„æµ‹çš„å­—ç¬¦
    loss.backward()  # åå‘ä¼ æ’­
    optimizer.step()  # æ›´æ–°å‚æ•°
    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))
```

**è¿è¡Œç»“æœï¼š**

    Predicted string:hehee, Epoch [1/15] loss: 8.2711
    Predicted string:olhll, Epoch [2/15] loss: 6.2931
    Predicted string:ollll, Epoch [3/15] loss: 5.3395
    Predicted string:ollll, Epoch [4/15] loss: 4.7223
    Predicted string:ohlll, Epoch [5/15] loss: 4.2614
    Predicted string:ohlll, Epoch [6/15] loss: 3.9137
    Predicted string:ohlol, Epoch [7/15] loss: 3.6579
    Predicted string:ohlol, Epoch [8/15] loss: 3.4601
    Predicted string:ohlol, Epoch [9/15] loss: 3.2896
    Predicted string:ohlol, Epoch [10/15] loss: 3.1306
    Predicted string:ohlol, Epoch [11/15] loss: 2.9806
    Predicted string:ohlol, Epoch [12/15] loss: 2.8476
    Predicted string:ohlol, Epoch [13/15] loss: 2.7450
    Predicted string:ohlol, Epoch [14/15] loss: 2.6792
    Predicted string:ohlol, Epoch [15/15] loss: 2.6347

## 3.2 ä½¿ç”¨RNN

åœ¨ä»£ç ä¸­ï¼Œé¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªRNNæ¨¡å‹çš„ç±»`Model`ï¼Œç»§æ‰¿è‡ª`torch.nn.Module`ã€‚è¿™ä¸ªæ¨¡å‹æ¥å—ä¸€ä¸ª`input_size`è¡¨ç¤ºè¾“å…¥çš„å‘é‡ç»´åº¦ï¼Œä¸€ä¸ª`hidden_size`è¡¨ç¤ºéšè—å±‚çš„å‘é‡ç»´åº¦ï¼Œä¸€ä¸ª`batch_size`è¡¨ç¤ºæ¯æ‰¹æ¬¡è¾“å…¥æ•°æ®çš„æ ·æœ¬æ•°é‡ï¼Œä»¥åŠä¸€ä¸ªå¯é€‰çš„`num_layers`è¡¨ç¤ºRNNçš„å±‚æ•°ã€‚

åœ¨è¿™ä¸ªç±»ä¸­ï¼Œå®šä¹‰äº†ä¸€ä¸ªRNNå±‚`self.rnn`ï¼Œè¾“å…¥ä¸º`input_size`å’Œ`hidden_size`ï¼Œå¹¶æŒ‡å®šå±‚æ•°ä¸º`num_layers`ã€‚åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå°†è¾“å…¥æ•°æ®`input`å’Œä¸€ä¸ªå…¨é›¶å¼ é‡`hidden`è¾“å…¥åˆ°RNNå±‚ä¸­ï¼Œç„¶åå°†è¾“å‡ºå¼ é‡`out`ä»ä¸‰ç»´å¼ é‡è½¬æ¢ä¸ºäºŒç»´å¼ é‡ï¼Œå¹¶è¿”å›è¾“å‡ºå¼ é‡ã€‚

åœ¨è®­ç»ƒæ—¶ï¼Œé¦–å…ˆå°†ä¼˜åŒ–å™¨çš„æ¢¯åº¦æ¸…é›¶ï¼Œç„¶åå°†è¾“å…¥æ•°æ®`inputs`é€å…¥æ¨¡å‹ä¸­å¾—åˆ°è¾“å‡º`outputs`ã€‚å°†è¾“å‡º`outputs`å’Œæ ‡ç­¾`labels`è¾“å…¥åˆ°äº¤å‰ç†µæŸå¤±å‡½æ•°ä¸­è®¡ç®—æŸå¤±ï¼Œç„¶åé€šè¿‡åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ï¼Œå¹¶è°ƒç”¨ä¼˜åŒ–å™¨çš„`step`æ–¹æ³•æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

æœ€åï¼Œå°†è¾“å‡º`outputs`ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹ç»“æœå–å‡ºæ¥ï¼Œè½¬æ¢ä¸ºå¯¹åº”çš„å­—ç¬¦ï¼Œæ‰“å°å‡ºæ¥ã€‚åŒæ—¶ï¼Œè¾“å‡ºå½“å‰çš„æŸå¤±å’Œè®­ç»ƒè½®æ•°ã€‚


```python
import torch

# 1ã€ç¡®å®šå‚æ•°
seq_len = 5
input_size = 4
hidden_size = 4
batch_size = 1

# 2ã€å‡†å¤‡æ•°æ®
index2char = ['e', 'h', 'l', 'o']  #å­—å…¸
x_data = [1, 0, 2, 2, 3]  #ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello
y_data = [3, 1, 2, 3, 2]  #æ ‡ç­¾ï¼šohlol

one_hot_lookup = [[1, 0, 0, 0],  # ç”¨æ¥å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡çš„å‚ç…§è¡¨
                  [0, 1, 0, 0],
                  [0, 0, 1, 0],
                  [0, 0, 0, 1]]
x_one_hot = [one_hot_lookup[x] for x in x_data]  #å°†x_dataè½¬æ¢ä¸ºone-hotå‘é‡
inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size,
                                      input_size)  #(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’,ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’Šğ’ğ’‘ğ’–ğ’•ğ‘ºğ’Šğ’›ğ’†)
labels = torch.LongTensor(y_data)


# 3ã€æ„å»ºæ¨¡å‹
class Model(torch.nn.Module):
    def __init__(self, input_size, hidden_size, batch_size, num_layers=1):
        super(Model, self).__init__()
        self.num_layers = num_layers
        self.batch_size = batch_size
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.rnn = torch.nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers)

    def forward(self, input):
        hidden = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)
        out, _ = self.rnn(input, hidden)  # out: tensor of shape (seq_len, batch, hidden_size)
        return out.view(-1, self.hidden_size)  # å°†è¾“å‡ºçš„ä¸‰ç»´å¼ é‡è½¬æ¢ä¸ºäºŒç»´å¼ é‡,(ğ’”ğ’†ğ’’ğ‘³ğ’†ğ’Ã—ğ’ƒğ’‚ğ’•ğ’„ğ’‰ğ‘ºğ’Šğ’›ğ’†,ğ’‰ğ’Šğ’…ğ’…ğ’†ğ’ğ‘ºğ’Šğ’›ğ’†)

    def init_hidden(self):  #åˆå§‹åŒ–éšè—å±‚ï¼Œéœ€è¦batch_size
        return torch.zeros(self.batch_size, self.hidden_size)


net = Model(input_size, hidden_size, batch_size, num_layers)

# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=0.05)  # Adamä¼˜åŒ–å™¨

# 5ã€è®­ç»ƒ
for epoch in range(15):
    optimizer.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    _, idx = outputs.max(dim=1)
    idx = idx.data.numpy()
    print('Predicted string: ', ''.join([index2char[x] for x in idx]), end='')
    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))
```

**è¿è¡Œç»“æœï¼š**

    Predicted string:  hhhhh, Epoch [1/15] loss: 1.4325
    Predicted string:  hhhhh, Epoch [2/15] loss: 1.2532
    Predicted string:  ohhoh, Epoch [3/15] loss: 1.1057
    Predicted string:  ohlol, Epoch [4/15] loss: 0.9970
    Predicted string:  ohlol, Epoch [5/15] loss: 0.9208
    Predicted string:  oolol, Epoch [6/15] loss: 0.8669
    Predicted string:  oolol, Epoch [7/15] loss: 0.8250
    Predicted string:  oolol, Epoch [8/15] loss: 0.7863
    Predicted string:  oolol, Epoch [9/15] loss: 0.7453
    Predicted string:  oolol, Epoch [10/15] loss: 0.7024
    Predicted string:  oolol, Epoch [11/15] loss: 0.6625
    Predicted string:  oolol, Epoch [12/15] loss: 0.6291
    Predicted string:  ohlol, Epoch [13/15] loss: 0.6026
    Predicted string:  ohlol, Epoch [14/15] loss: 0.5812
    Predicted string:  ohlol, Epoch [15/15] loss: 0.5630

åœ¨è¿™æ®µä»£ç ä¸­ï¼Œ`labels`ä¸éœ€è¦è¿›è¡Œ`.view(-1, 1)`å¤„ç†çš„åŸå› æ˜¯å› ä¸ºå®ƒæ˜¯ä¸€ä¸ªä¸€ç»´çš„`LongTensor`å¼ é‡ï¼Œå½¢çŠ¶ä¸º`(seq_len,)`ã€‚åœ¨ PyTorch çš„äº¤å‰ç†µæŸå¤±å‡½æ•° `torch.nn.CrossEntropyLoss()` ä¸­ï¼Œæ ‡ç­¾éœ€è¦è¢«è¡¨ç¤ºæˆä¸€ç»´çš„é•¿æ•´å‹å¼ é‡ã€‚è¿™æ˜¯å› ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°åœ¨å†…éƒ¨å°†æ ‡ç­¾è¿›è¡Œäº†one-hotç¼–ç ï¼Œå¹¶ä½¿ç”¨è¿™äº›ç¼–ç æ¥è®¡ç®—é¢„æµ‹å€¼å’Œæ ‡ç­¾ä¹‹é—´çš„æŸå¤±ã€‚

åœ¨è¿™æ®µä»£ç ä¸­ï¼Œç”±äº `labels` æ˜¯ä¸€ä¸ªä¸€ç»´å¼ é‡ï¼Œå› æ­¤æ— éœ€è¿›è¡Œå½¢çŠ¶å˜æ¢ã€‚å½“ç„¶ï¼Œå¦‚æœä½ å°† `labels` è½¬æ¢ä¸º `(seq_len, 1)` çš„å½¢çŠ¶ä¹Ÿå¯ä»¥ï¼Œä½†æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`torch.nn.CrossEntropyLoss()` ä¼šè‡ªåŠ¨å°†å…¶è½¬æ¢å›ä¸€ç»´å¼ é‡ï¼Œæ‰€ä»¥ä¸å¿…è¿›è¡Œæ­¤æ“ä½œã€‚

## 3.3 ä½¿ç”¨embedding and linear layer

åœ¨ä½¿ç”¨ç‹¬çƒ­ç¼–ç ä½œä¸ºRNNè¾“å…¥æ—¶ï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªç¼ºç‚¹ï¼š

1. ç»´åº¦ç¾éš¾ï¼šå¯¹äºå¤§è§„æ¨¡çš„æ•°æ®é›†å’Œå¤šç±»åˆ†ç±»é—®é¢˜ï¼Œç‹¬çƒ­ç¼–ç ä¼šå¯¼è‡´è¾“å…¥æ•°æ®ç»´åº¦æåº¦è†¨èƒ€ï¼Œä»è€Œå¯¼è‡´æ¨¡å‹å‚æ•°å˜å¾—éå¸¸åºå¤§ï¼Œè®­ç»ƒå’Œæ¨ç†æ—¶é—´å˜æ…¢ã€‚
2. æ•°æ®ç¨€ç–æ€§ï¼šç‹¬çƒ­ç¼–ç ä¼šä½¿å¾—å¤§éƒ¨åˆ†è¾“å…¥éƒ½æ˜¯0ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªä½ç½®æ˜¯1ï¼Œè¿™å¯¼è‡´è¾“å…¥æ•°æ®éå¸¸ç¨€ç–ï¼Œæµªè´¹äº†å¤§é‡çš„å­˜å‚¨ç©ºé—´å’Œè®¡ç®—èµ„æºã€‚
3. æ— æ³•è¡¨è¾¾åºåˆ—ä¿¡æ¯ï¼šåœ¨RNNä¸­ï¼Œåºåˆ—çš„é¡ºåºå¾ˆé‡è¦ï¼Œä½†æ˜¯ç‹¬çƒ­ç¼–ç æ— æ³•è¡¨è¾¾åºåˆ—ä¿¡æ¯ï¼Œåªèƒ½è¡¨è¾¾æ¯ä¸ªè¾“å…¥åœ¨ç±»åˆ«ä¸Šçš„å·®å¼‚ã€‚å› æ­¤ï¼Œåœ¨å¤„ç†åºåˆ—æ•°æ®æ—¶ï¼Œç‹¬çƒ­ç¼–ç å¯èƒ½æ— æ³•æ•æ‰åˆ°åºåˆ—ä¸­çš„æ¨¡å¼å’Œè§„å¾‹ã€‚
4. æ— æ³•å¤„ç†æœªçŸ¥ç±»åˆ«ï¼šç‹¬çƒ­ç¼–ç éœ€è¦é¢„å…ˆçŸ¥é“ç±»åˆ«çš„æ•°é‡ï¼Œå¦‚æœé‡åˆ°æ–°çš„ç±»åˆ«ï¼Œéœ€è¦é‡æ–°æ‰©å±•ç¼–ç å‘é‡ï¼Œè¿™ä¼šå¸¦æ¥é¢å¤–çš„å¼€é”€å’Œå¤æ‚åº¦ã€‚

å› æ­¤ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å…¶ä»–çš„ç¼–ç æ–¹å¼æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œä¾‹å¦‚ä½¿ç”¨**åµŒå…¥ï¼ˆembeddingï¼‰å‘é‡**æ¥è¡¨ç¤ºè¾“å…¥æ•°æ®ï¼Œæˆ–è€…ä½¿ç”¨ç‰¹å¾å“ˆå¸Œï¼ˆfeature hashingï¼‰ç­‰æŠ€æœ¯æ¥é™ä½ç»´åº¦ã€‚

![image-20230423135726064](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231357158.png)

### åµŒå…¥ï¼ˆembeddingï¼‰å‘é‡

åµŒå…¥ï¼ˆembeddingï¼‰å‘é‡æ˜¯ä¸€ç§å°†ç¦»æ•£å‹æ•°æ®ï¼ˆå¦‚è¯è¯­ã€ç”¨æˆ·IDç­‰ï¼‰æ˜ å°„åˆ°è¿ç»­å‹å‘é‡ç©ºé—´ä¸­çš„æŠ€æœ¯ï¼Œå¸¸ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€æ¨èç³»ç»Ÿç­‰é¢†åŸŸã€‚

**åµŒå…¥å‘é‡çš„åŸç†æ˜¯åˆ©ç”¨ç¥ç»ç½‘ç»œä¸­çš„ä¸€å±‚æˆ–å¤šå±‚è¿›è¡Œæ˜ å°„ã€‚**å‡è®¾æœ‰nä¸ªç¦»æ•£åŒ–çš„å…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ ç”¨ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°è¿›è¡Œç¼–ç ã€‚åµŒå…¥å±‚çš„è¾“å…¥æ˜¯è¿™äº›ç¼–ç ï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªç¼–ç å¯¹åº”çš„kç»´åµŒå…¥å‘é‡ï¼Œé€šå¸¸kçš„å€¼ä¼šè¿œå°äºnï¼Œå› æ­¤å°†æ•°æ®ä»ä¸€ä¸ªå¤§çš„é«˜ç»´ç©ºé—´å‹ç¼©åˆ°ä¸€ä¸ªè¾ƒå°çš„ä½ç»´ç©ºé—´ã€‚

åœ¨åµŒå…¥å±‚ä¸­ï¼Œæ¯ä¸ªå…ƒç´ çš„ç¼–ç éƒ½è¢«æ˜ å°„ä¸ºä¸€ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡ï¼Œä¸”ä¸åŒå…ƒç´ çš„å‘é‡ä¹‹é—´å¯ä»¥è®¡ç®—ç›¸ä¼¼åº¦ï¼Œè¿™ä¸ªç›¸ä¼¼åº¦åœ¨ä¸€å®šç¨‹åº¦ä¸Šåæ˜ äº†å®ƒä»¬åœ¨åŸå§‹æ•°æ®ä¸­çš„å…³ç³»ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œç›¸ä¼¼çš„å•è¯ï¼ˆå¦‚â€œcatâ€å’Œâ€œdogâ€ï¼‰åœ¨åµŒå…¥ç©ºé—´ä¸­çš„å‘é‡ä¼šæ›´åŠ æ¥è¿‘ï¼Œå› ä¸ºå®ƒä»¬åœ¨è¯­ä¹‰ä¸Šæœ‰ä¸€å®šçš„ç›¸å…³æ€§ã€‚

![image-20230423140105849](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231401930.png)

åµŒå…¥å‘é‡åœ¨è®¸å¤šåº”ç”¨ä¸­è¢«å¹¿æ³›ä½¿ç”¨ï¼Œä¾‹å¦‚è¯­è¨€æ¨¡å‹ã€æƒ…æ„Ÿåˆ†æã€æ¨èç³»ç»Ÿç­‰ã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œé€šè¿‡ä½¿ç”¨åµŒå…¥å‘é‡å¯ä»¥å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ï¼Œä»è€Œæ–¹ä¾¿æœºå™¨å­¦ä¹ ç®—æ³•å¤„ç†ã€‚åŒæ—¶ï¼Œç”±äºåµŒå…¥å‘é‡çš„ä½ç»´åº¦è¡¨ç¤ºï¼Œè®¡ç®—é€Ÿåº¦è¾ƒå¿«ï¼Œå¯ä»¥å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ã€‚

![image-20230423140241004](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231402102.png)

### ç›¸å…³å‡½æ•°

![image-20230423141828128](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231418221.png)

![image-20230423141848208](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231418293.png)

![image-20230423141912482](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231419567.png)

### ä»£ç 

è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªåŸºäºRNNçš„å­—ç¬¦çº§åˆ«çš„è¯­è¨€æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹ç»™å®šè¾“å…¥å­—ç¬¦åºåˆ—çš„ä¸‹ä¸€ä¸ªå­—ç¬¦ã€‚ä¸‹é¢æ˜¯å¯¹ä»£ç çš„è§£é‡Šå’Œè¯´æ˜ï¼š

1. åœ¨ç¡®å®šå‚æ•°çš„éƒ¨åˆ†ï¼Œå®šä¹‰äº†RNNçš„è¾“å…¥å’Œè¾“å‡ºå¤§å°ã€éšè—çŠ¶æ€çš„ç»´åº¦ã€Embeddingå‘é‡çš„å¤§å°ã€RNNå±‚æ•°ç­‰å‚æ•°ï¼Œè¿™äº›å‚æ•°å°†ä¼šåœ¨æ¨¡å‹çš„æ„å»ºä¸­ä½¿ç”¨ã€‚
2. åœ¨å‡†å¤‡æ•°æ®çš„éƒ¨åˆ†ï¼Œå®šä¹‰äº†ä¸€ä¸ªå­—å…¸`index2char`ç”¨äºå°†æ•°å­—ç´¢å¼•æ˜ å°„åˆ°å­—ç¬¦ï¼Œè¾“å…¥æ•°æ®`x_data`æ˜¯ä¸€æ®µè‹±æ–‡å­—ç¬¦ä¸²"hello"ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°å­—ç´¢å¼•çš„å½¢å¼ã€‚
3. åœ¨æ„å»ºæ¨¡å‹çš„éƒ¨åˆ†ï¼Œä½¿ç”¨äº†PyTorchä¸­çš„`Embedding`å±‚å°†è¾“å…¥å­—ç¬¦çš„æ•°å­—ç´¢å¼•è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„å‘é‡è¡¨ç¤ºï¼Œè¯¥å‘é‡è¡¨ç¤ºå°†åœ¨RNNä¸­ä¼ é€’ã€‚ä½¿ç”¨`RNN`å±‚å°†Embeddingå‘é‡ä½œä¸ºè¾“å…¥ï¼Œè®¡ç®—RNNçš„è¾“å‡ºã€‚æœ€åï¼Œé€šè¿‡ä¸€ä¸ªå…¨è¿æ¥å±‚`fc`å°†RNNçš„è¾“å‡ºæ˜ å°„åˆ°æ¯ä¸ªå­—ç¬¦çš„æ¦‚ç‡åˆ†å¸ƒã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œå…¨è¿æ¥å±‚çš„ä½œç”¨æ˜¯å¯¹RNNçš„è¾“å‡ºåšä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œä»è€Œå°†è¾“å‡ºçš„ç»´åº¦ä»éšè—çŠ¶æ€çš„ç»´åº¦å˜ä¸ºæ¯ä¸ªå­—ç¬¦çš„æ•°é‡ã€‚
4. åœ¨å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨çš„éƒ¨åˆ†ï¼Œä½¿ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°ä½œä¸ºæ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼ŒAdamä¼˜åŒ–å™¨æ¥æ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚
5. åœ¨è®­ç»ƒæ¨¡å‹çš„éƒ¨åˆ†ï¼Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¾ªç¯è¿›è¡Œæ¨¡å‹çš„è®­ç»ƒï¼Œæ¯æ¬¡è®­ç»ƒè¾“å‡ºå½“å‰è®­ç»ƒæ¬¡æ•°å’ŒæŸå¤±å€¼ï¼Œå¹¶æ‰“å°å‡ºæ¨¡å‹é¢„æµ‹çš„å­—ç¬¦ä¸²ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªå­—ç¬¦çš„Embeddingå‘é‡ä¼šéšç€è®­ç»ƒä¸æ–­è°ƒæ•´ï¼Œæœ€ç»ˆä½¿æ¨¡å‹èƒ½å¤Ÿå¯¹å­—ç¬¦åºåˆ—åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚


```python
import torch

# 1ã€ç¡®å®šå‚æ•°
num_class = 4
input_size = 4
hidden_size = 8
embedding_size = 10
num_layers = 2
batch_size = 1
seq_len = 5

# 2ã€å‡†å¤‡æ•°æ®
index2char = ['e', 'h', 'l', 'o']  #å­—å…¸
x_data = [[1, 0, 2, 2, 3]]  # (batch_size, seq_len) ç”¨å­—å…¸ä¸­çš„ç´¢å¼•ï¼ˆæ•°å­—ï¼‰è¡¨ç¤ºæ¥è¡¨ç¤ºhello
y_data = [3, 1, 2, 3, 2]  #  (batch_size * seq_len) æ ‡ç­¾ï¼šohlol

inputs = torch.LongTensor(x_data)  # (batch_size, seq_len)
labels = torch.LongTensor(y_data)  # (batch_size * seq_len)


# 3ã€æ„å»ºæ¨¡å‹
class Model(torch.nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.emb = torch.nn.Embedding(num_class, embedding_size)
        self.rnn = torch.nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers,
                                batch_first=True)
        self.fc = torch.nn.Linear(hidden_size, num_class)

    def forward(self, x):
        hidden = torch.zeros(num_layers, x.size(0), hidden_size)  # (num_layers, batch_size, hidden_size)
        x = self.emb(x)  # è¿”å›(batch_size, seq_len, embedding_size)
        x, _ = self.rnn(x, hidden)  # è¿”å›(batch_size, seq_len, hidden_size)
        x = self.fc(x)  # è¿”å›(batch_size, seq_len, num_class)
        return x.view(-1, num_class)  # (batch_size * seq_len, num_class)


net = Model()

# 4ã€æŸå¤±å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters(), lr=0.05)  # Adamä¼˜åŒ–å™¨

# 5ã€è®­ç»ƒ
for epoch in range(15):
    optimizer.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    _, idx = outputs.max(dim=1)
    idx = idx.data.numpy()
    print('Predicted string: ', ''.join([index2char[x] for x in idx]), end='')
    print(', Epoch [%d/15] loss: %.4f' % (epoch + 1, loss.item()))
```

**è¿è¡Œç»“æœï¼š**

    Predicted string:  eeeee, Epoch [1/15] loss: 1.5407
    Predicted string:  oolol, Epoch [2/15] loss: 1.1158
    Predicted string:  oolol, Epoch [3/15] loss: 0.9047
    Predicted string:  ohlol, Epoch [4/15] loss: 0.7391
    Predicted string:  lhlol, Epoch [5/15] loss: 0.6006
    Predicted string:  ohlol, Epoch [6/15] loss: 0.4833
    Predicted string:  ohlol, Epoch [7/15] loss: 0.3581
    Predicted string:  ohlol, Epoch [8/15] loss: 0.2540
    Predicted string:  ohlol, Epoch [9/15] loss: 0.1921
    Predicted string:  ohlol, Epoch [10/15] loss: 0.1351
    Predicted string:  ohlol, Epoch [11/15] loss: 0.0972
    Predicted string:  ohlol, Epoch [12/15] loss: 0.0752
    Predicted string:  ohlol, Epoch [13/15] loss: 0.0594
    Predicted string:  ohlol, Epoch [14/15] loss: 0.0465
    Predicted string:  ohlol, Epoch [15/15] loss: 0.0363

# 4 LSTMå’ŒGRU

ä¸Šé¢ RNN æ¨¡å‹ä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ï¼š

1. **æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜**ï¼šå½“åºåˆ—éå¸¸é•¿æ—¶ï¼Œæ¢¯åº¦å¯èƒ½ä¼šé€æ¸æ¶ˆå¤±æˆ–çˆ†ç‚¸ï¼Œå¯¼è‡´ç½‘ç»œæ— æ³•å­¦ä¹ é•¿åºåˆ—çš„ä¾èµ–å…³ç³»ã€‚

2. **åªèƒ½å­¦ä¹ å›ºå®šé•¿åº¦çš„åºåˆ—**ï¼šç”±äº RNN çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯å›ºå®šé•¿åº¦çš„ï¼Œå› æ­¤æ¨¡å‹åªèƒ½å­¦ä¹ å›ºå®šé•¿åº¦çš„åºåˆ—ã€‚

3. **å¤„ç†ä¸åŒæ—¶é—´æ­¥çš„è¾“å…¥æ—¶å­˜åœ¨æ•°æ®å¯¹é½é—®é¢˜**ï¼šåœ¨è®­ç»ƒ RNN æ—¶ï¼Œéœ€è¦å°†ä¸åŒé•¿åº¦çš„åºåˆ—å¯¹é½åˆ°ç›¸åŒçš„é•¿åº¦ï¼Œè¿™é€šå¸¸éœ€è¦ä¸€äº›é¢„å¤„ç†å’Œåå¤„ç†ï¼Œè€Œä¸”å¯èƒ½ä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±æˆ–å™ªå£°å¼•å…¥ã€‚

4. **æ— æ³•å¾ˆå¥½åœ°å¤„ç†é•¿æœŸä¾èµ–å…³ç³»**ï¼šå°½ç®¡ RNN å¯ä»¥å­¦ä¹ ä¸€å®šçš„åºåˆ—ä¾èµ–æ€§ï¼Œä½†æ˜¯å½“åºåˆ—çš„æ—¶é—´è·¨åº¦å¾ˆå¤§æ—¶ï¼ŒRNN å¯èƒ½ä¼šå‡ºç°é•¿æœŸä¾èµ–é—®é¢˜ã€‚æ­¤å¤–ï¼Œç”±äº RNN çš„å¾ªç¯ç»“æ„ï¼Œæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºéƒ½ä¾èµ–äºå‰ä¸€æ—¶é—´æ­¥çš„çŠ¶æ€ï¼Œå› æ­¤æ¨¡å‹å¯èƒ½ä¼šå—åˆ°æŸäº›æ—¶é—´æ­¥çš„ä¿¡æ¯å¹²æ‰°ã€‚

æœ‰å‡ ç§æ–¹æ³•å¯ä»¥å°è¯•è§£å†³RNNæ¨¡å‹çš„ä¸€äº›å±€é™æ€§ï¼š

1. **ä½¿ç”¨æ›´é«˜çº§åˆ«çš„æ¨¡å‹**ï¼šå¯ä»¥ä½¿ç”¨ä¸€äº›æ›´å…ˆè¿›çš„æ¨¡å‹ï¼Œ==**å¦‚LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰å’ŒGRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰ç­‰**==ï¼Œè¿™äº›æ¨¡å‹åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†RNNæ¨¡å‹å­˜åœ¨çš„ä¸€äº›é—®é¢˜ã€‚
2. **æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶**ï¼šæ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å¸®åŠ©æ¨¡å‹åœ¨è¾“å…¥åºåˆ—ä¸­å…³æ³¨ä¸åŒçš„éƒ¨åˆ†ï¼Œå¹¶å¯¹é‡è¦çš„éƒ¨åˆ†è¿›è¡ŒåŠ æƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
3. **ä½¿ç”¨æ›´å¤šçš„æ•°æ®**ï¼šå¢åŠ æ•°æ®é‡å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ è¾“å…¥åºåˆ—çš„è§„å¾‹ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
4. **å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†**ï¼šå¯¹è¾“å…¥æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œå¦‚å½’ä¸€åŒ–ã€é™å™ªã€å¹³æ»‘ç­‰ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚
5. **ç»“åˆå…¶ä»–æŠ€æœ¯**ï¼šå¯ä»¥ç»“åˆå…¶ä»–æŠ€æœ¯æ¥è§£å†³æ¨¡å‹å­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚é›†æˆå­¦ä¹ ã€æ­£åˆ™åŒ–ã€Dropoutç­‰ã€‚

LSTMï¼ˆLong Short-Term Memoryï¼Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰å’ŒGRUï¼ˆGated Recurrent Unitï¼Œé—¨æ§å¾ªç¯å•å…ƒï¼‰æ˜¯å¸¸ç”¨çš„å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰çš„å˜ç§ï¼Œç›¸æ¯”äºä¼ ç»Ÿçš„RNNï¼Œå®ƒä»¬èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†é•¿åºåˆ—æ•°æ®ï¼Œè§£å†³äº†ä¼ ç»ŸRNNä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚

LSTMçš„ä¸»è¦æ€æƒ³æ˜¯å¼•å…¥ä¸€ä¸ªç§°ä¸ºâ€œç»†èƒçŠ¶æ€â€ï¼ˆcell stateï¼‰çš„è®°å¿†å•å…ƒï¼Œä»¥åŠä¸‰ä¸ªé—¨ï¼ˆè¾“å…¥é—¨ã€é—å¿˜é—¨å’Œè¾“å‡ºé—¨ï¼‰æ¥æ§åˆ¶å¯¹ç»†èƒçŠ¶æ€çš„è®¿é—®å’Œæ›´æ–°ã€‚å…¶ä¸­ï¼Œè¾“å…¥é—¨å†³å®šäº†æ–°çš„è¾“å…¥å¦‚ä½•å½±å“ç»†èƒçŠ¶æ€ï¼Œé—å¿˜é—¨å†³å®šäº†ä½•æ—¶å¿˜è®°æ—§çš„ç»†èƒçŠ¶æ€ï¼Œè¾“å‡ºé—¨å†³å®šäº†è¾“å‡ºä»€ä¹ˆæ ·çš„ä¿¡æ¯ã€‚LSTMçš„ç»“æ„ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºå’Œè®­ç»ƒæ—¶é—´ã€‚

GRUæ˜¯ç”±Choç­‰äººäº2014å¹´æå‡ºçš„ä¸€ç§è½»é‡çº§çš„é—¨æ§å¾ªç¯å•å…ƒï¼Œå®ƒåªåŒ…å«ä¸¤ä¸ªé—¨ï¼ˆæ›´æ–°é—¨å’Œé‡ç½®é—¨ï¼‰ï¼Œé€šè¿‡æ§åˆ¶è¾“å…¥å’Œå†å²çŠ¶æ€çš„æƒé‡æ¥æ§åˆ¶ä¿¡æ¯æµåŠ¨ã€‚GRUçš„ç»“æ„æ¯”LSTMç®€å•ï¼Œè®¡ç®—é‡ä¹Ÿç›¸å¯¹è¾ƒå°ï¼ŒåŒæ—¶åœ¨å¤„ç†é•¿åºåˆ—æ•°æ®æ—¶ä¹Ÿå…·æœ‰ä¸é”™çš„æ•ˆæœã€‚

æ€»çš„æ¥è¯´ï¼ŒLSTMå’ŒGRUæ˜¯ç›®å‰åœ¨å¾ªç¯ç¥ç»ç½‘ç»œé¢†åŸŸä¸­è¡¨ç°ä¼˜å¼‚çš„æ¨¡å‹ï¼Œä½†å…·ä½“é€‰æ‹©å“ªç§æ¨¡å‹éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†æ¥å†³å®šã€‚

- **LSTMåŸç†ç¤ºæ„å›¾**

  ç›¸å…³é“¾æ¥ï¼š[å¦‚ä½•ä»RNNèµ·æ­¥ï¼Œä¸€æ­¥ä¸€æ­¥é€šä¿—ç†è§£LSTM](https://blog.csdn.net/v_JULY_v/article/details/89894058)

![image-20230423142703707](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231427812.png)

![image-20230423142740832](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231427920.png)

- **GRUåŸç†ç¤ºæ„å›¾**

  ç›¸å…³é“¾æ¥ï¼š[äººäººéƒ½èƒ½çœ‹æ‡‚çš„GRU](https://zhuanlan.zhihu.com/p/32481747)

  ![image-20230423142842256](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231428349.png)

  ![image-20230423142911736](https://gitee.com/SolarLv/my-image-host/raw/master/img/202304231429822.png)
